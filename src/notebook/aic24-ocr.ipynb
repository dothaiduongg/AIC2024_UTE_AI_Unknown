{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-08-14T15:12:24.588815Z","iopub.status.busy":"2024-08-14T15:12:24.587184Z","iopub.status.idle":"2024-08-14T15:18:44.746731Z","shell.execute_reply":"2024-08-14T15:18:44.744282Z","shell.execute_reply.started":"2024-08-14T15:12:24.588744Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\n","jupyterlab 4.2.3 requires httpx>=0.25.0, but you have httpx 0.13.3 which is incompatible.\n","jupyterlab 4.2.3 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\n","jupyterlab-lsp 5.1.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\n","tensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.4.1 which is incompatible.\n","ydata-profiling 4.6.4 requires numpy<1.26,>=1.16.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mCollecting bitsandbytes\n","  Downloading bitsandbytes-0.43.3-py3-none-manylinux_2_24_x86_64.whl.metadata (3.5 kB)\n","Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from bitsandbytes) (2.1.2+cpu)\n","Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from bitsandbytes) (1.26.4)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.13.1)\n","Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (4.9.0)\n","Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (1.13.0)\n","Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.2.1)\n","Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.1.2)\n","Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (2024.5.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->bitsandbytes) (2.1.3)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->bitsandbytes) (1.3.0)\n","Downloading bitsandbytes-0.43.3-py3-none-manylinux_2_24_x86_64.whl (137.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.5/137.5 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hInstalling collected packages: bitsandbytes\n","Successfully installed bitsandbytes-0.43.3\n","Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.42.3)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.13.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.23.4)\n","Requirement already satisfied: numpy<2.0,>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\n","Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.12.25)\n","Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\n","Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.3)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.19.1)\n","Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\n","Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.5.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.9.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.7.4)\n","Collecting flash-attn\n","  Downloading flash_attn-2.6.3.tar.gz (2.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25lerror\n","  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n","  \n","  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n","  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n","  \u001b[31m╰─>\u001b[0m \u001b[31m[20 lines of output]\u001b[0m\n","  \u001b[31m   \u001b[0m fatal: not a git repository (or any of the parent directories): .git\n","  \u001b[31m   \u001b[0m /tmp/pip-install-m286qa8f/flash-attn_22a8b41dcd814b92ba8597423f52d4df/setup.py:95: UserWarning: flash_attn was requested, but nvcc was not found.  Are you sure your environment has nvcc available?  If you're installing within a container from https://hub.docker.com/r/pytorch/pytorch, only images whose names contain 'devel' will provide nvcc.\n","  \u001b[31m   \u001b[0m   warnings.warn(\n","  \u001b[31m   \u001b[0m Traceback (most recent call last):\n","  \u001b[31m   \u001b[0m   File \"<string>\", line 2, in <module>\n","  \u001b[31m   \u001b[0m   File \"<pip-setuptools-caller>\", line 34, in <module>\n","  \u001b[31m   \u001b[0m   File \"/tmp/pip-install-m286qa8f/flash-attn_22a8b41dcd814b92ba8597423f52d4df/setup.py\", line 179, in <module>\n","  \u001b[31m   \u001b[0m     CUDAExtension(\n","  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/torch/utils/cpp_extension.py\", line 1076, in CUDAExtension\n","  \u001b[31m   \u001b[0m     library_dirs += library_paths(cuda=True)\n","  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/torch/utils/cpp_extension.py\", line 1203, in library_paths\n","  \u001b[31m   \u001b[0m     if (not os.path.exists(_join_cuda_home(lib_dir)) and\n","  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/torch/utils/cpp_extension.py\", line 2416, in _join_cuda_home\n","  \u001b[31m   \u001b[0m     raise OSError('CUDA_HOME environment variable is not set. '\n","  \u001b[31m   \u001b[0m OSError: CUDA_HOME environment variable is not set. Please set it to your CUDA install root.\n","  \u001b[31m   \u001b[0m \n","  \u001b[31m   \u001b[0m \n","  \u001b[31m   \u001b[0m torch.__version__  = 2.1.2+cpu\n","  \u001b[31m   \u001b[0m \n","  \u001b[31m   \u001b[0m \n","  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n","  \n","  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n","\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n","\n","\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n","\u001b[31m╰─>\u001b[0m See above for output.\n","\n","\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n","\u001b[1;36mhint\u001b[0m: See above for details.\n","\u001b[?25hCollecting sentence-transformers\n","  Downloading sentence_transformers-3.0.1-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: transformers<5.0.0,>=4.34.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (4.42.3)\n","Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (4.66.4)\n","Requirement already satisfied: torch>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (2.1.2+cpu)\n","Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.26.4)\n","Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.2.2)\n","Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.11.4)\n","Requirement already satisfied: huggingface-hub>=0.15.1 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (0.23.4)\n","Requirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (9.5.0)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.13.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2024.5.0)\n","Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (21.3)\n","Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0.1)\n","Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.32.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.9.0)\n","Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (1.13.0)\n","Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.2.1)\n","Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.2)\n","Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (2023.12.25)\n","Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.4.3)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.19.1)\n","Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (3.2.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub>=0.15.1->sentence-transformers) (3.1.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2024.7.4)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n","Downloading sentence_transformers-3.0.1-py3-none-any.whl (227 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.1/227.1 kB\u001b[0m \u001b[31m162.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:01\u001b[0m\n","\u001b[?25hInstalling collected packages: sentence-transformers\n","Successfully installed sentence-transformers-3.0.1\n","Collecting xformers\n","  Downloading xformers-0.0.27.post2-cp310-cp310-manylinux2014_x86_64.whl.metadata (1.0 kB)\n","Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from xformers) (1.26.4)\n","Collecting torch==2.4.0 (from xformers)\n","  Downloading torch-2.4.0-cp310-cp310-manylinux1_x86_64.whl.metadata (26 kB)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch==2.4.0->xformers) (3.13.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch==2.4.0->xformers) (4.9.0)\n","Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch==2.4.0->xformers) (1.13.0)\n","Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch==2.4.0->xformers) (3.2.1)\n","Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch==2.4.0->xformers) (3.1.2)\n","Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch==2.4.0->xformers) (2024.5.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.4.0->xformers)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.4.0->xformers)\n","  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.4.0->xformers)\n","  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.4.0->xformers)\n","  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.4.0->xformers)\n","  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.4.0->xformers)\n","  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.4.0->xformers)\n","  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.4.0->xformers)\n","  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.4.0->xformers)\n","  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-nccl-cu12==2.20.5 (from torch==2.4.0->xformers)\n","  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n","Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.4.0->xformers)\n","  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n","Collecting triton==3.0.0 (from torch==2.4.0->xformers)\n","  Downloading triton-3.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch==2.4.0->xformers)\n","  Downloading nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch==2.4.0->xformers) (2.1.3)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch==2.4.0->xformers) (1.3.0)\n","Downloading xformers-0.0.27.post2-cp310-cp310-manylinux2014_x86_64.whl (20.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.8/20.8 MB\u001b[0m \u001b[31m59.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading torch-2.4.0-cp310-cp310-manylinux1_x86_64.whl (797.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m797.2/797.2 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m61.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m56.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading triton-3.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.4/209.4 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl (19.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hInstalling collected packages: triton, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, xformers\n","  Attempting uninstall: torch\n","    Found existing installation: torch 2.1.2+cpu\n","    Uninstalling torch-2.1.2+cpu:\n","      Successfully uninstalled torch-2.1.2+cpu\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","fastai 2.7.15 requires torch<2.4,>=1.10, but you have torch 2.4.0 which is incompatible.\n","torchaudio 2.1.2+cpu requires torch==2.1.2, but you have torch 2.4.0 which is incompatible.\n","torchtext 0.16.2+cpu requires torch==2.1.2, but you have torch 2.4.0 which is incompatible.\n","torchvision 0.16.2+cpu requires torch==2.1.2, but you have torch 2.4.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.6.20 nvidia-nvtx-cu12-12.1.105 torch-2.4.0 triton-3.0.0 xformers-0.0.27.post2\n","Collecting einops\n","  Downloading einops-0.8.0-py3-none-any.whl.metadata (12 kB)\n","Downloading einops-0.8.0-py3-none-any.whl (43 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.2/43.2 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: einops\n","Successfully installed einops-0.8.0\n"]}],"source":["!pip install -q translate\n","!pip install -q underthesea==1.3.5a3\n","!pip install -q underthesea[deep]\n","!pip install -q pyvi\n","!pip install -q langdetect\n","!pip install -q googletrans==3.1.0a0\n","!pip install -q peft\n","!pip install bitsandbytes\n","!pip install transformers\n","!pip install flash-attn\n","!pip install -U sentence-transformers\n","!pip install xformers\n","!pip install einops"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-08-15T01:05:31.791161Z","iopub.status.busy":"2024-08-15T01:05:31.790748Z","iopub.status.idle":"2024-08-15T01:06:08.837123Z","shell.execute_reply":"2024-08-15T01:06:08.835688Z","shell.execute_reply.started":"2024-08-15T01:05:31.791127Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting git+https://github.com/JaidedAI/EasyOCR.git\n","  Cloning https://github.com/JaidedAI/EasyOCR.git to /tmp/pip-req-build-omngnxam\n","  Running command git clone --filter=blob:none --quiet https://github.com/JaidedAI/EasyOCR.git /tmp/pip-req-build-omngnxam\n","  Resolved https://github.com/JaidedAI/EasyOCR.git to commit 3d3852d8e4ddd9e5044a6f70b561ca7186d9cbac\n","  Preparing metadata (setup.py) ... \u001b[?25ldone\n","\u001b[?25hRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from easyocr==1.7.1) (2.1.2+cpu)\n","Requirement already satisfied: torchvision>=0.5 in /opt/conda/lib/python3.10/site-packages (from easyocr==1.7.1) (0.16.2+cpu)\n","Requirement already satisfied: opencv-python-headless in /opt/conda/lib/python3.10/site-packages (from easyocr==1.7.1) (4.10.0.84)\n","Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from easyocr==1.7.1) (1.11.4)\n","Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from easyocr==1.7.1) (1.26.4)\n","Requirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from easyocr==1.7.1) (9.5.0)\n","Requirement already satisfied: scikit-image in /opt/conda/lib/python3.10/site-packages (from easyocr==1.7.1) (0.22.0)\n","Requirement already satisfied: python-bidi in /opt/conda/lib/python3.10/site-packages (from easyocr==1.7.1) (0.4.2)\n","Requirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from easyocr==1.7.1) (6.0.1)\n","Requirement already satisfied: Shapely in /opt/conda/lib/python3.10/site-packages (from easyocr==1.7.1) (1.8.5.post1)\n","Requirement already satisfied: pyclipper in /opt/conda/lib/python3.10/site-packages (from easyocr==1.7.1) (1.3.0.post5)\n","Requirement already satisfied: ninja in /opt/conda/lib/python3.10/site-packages (from easyocr==1.7.1) (1.11.1.1)\n","Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torchvision>=0.5->easyocr==1.7.1) (2.32.3)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->easyocr==1.7.1) (3.13.1)\n","Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch->easyocr==1.7.1) (4.9.0)\n","Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->easyocr==1.7.1) (1.13.0)\n","Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->easyocr==1.7.1) (3.2.1)\n","Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->easyocr==1.7.1) (3.1.2)\n","Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->easyocr==1.7.1) (2024.5.0)\n","Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from python-bidi->easyocr==1.7.1) (1.16.0)\n","Requirement already satisfied: imageio>=2.27 in /opt/conda/lib/python3.10/site-packages (from scikit-image->easyocr==1.7.1) (2.33.1)\n","Requirement already satisfied: tifffile>=2022.8.12 in /opt/conda/lib/python3.10/site-packages (from scikit-image->easyocr==1.7.1) (2023.12.9)\n","Requirement already satisfied: packaging>=21 in /opt/conda/lib/python3.10/site-packages (from scikit-image->easyocr==1.7.1) (21.3)\n","Requirement already satisfied: lazy_loader>=0.3 in /opt/conda/lib/python3.10/site-packages (from scikit-image->easyocr==1.7.1) (0.3)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=21->scikit-image->easyocr==1.7.1) (3.1.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->easyocr==1.7.1) (2.1.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision>=0.5->easyocr==1.7.1) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision>=0.5->easyocr==1.7.1) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision>=0.5->easyocr==1.7.1) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision>=0.5->easyocr==1.7.1) (2024.7.4)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->easyocr==1.7.1) (1.3.0)\n"]}],"source":["!pip install git+https://github.com/JaidedAI/EasyOCR.git"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-08-14T15:20:49.389345Z","iopub.status.busy":"2024-08-14T15:20:49.388632Z","iopub.status.idle":"2024-08-14T15:21:25.210394Z","shell.execute_reply":"2024-08-14T15:21:25.208992Z","shell.execute_reply.started":"2024-08-14T15:20:49.389298Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-08-14 15:20:58.334303: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-08-14 15:20:58.334550: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-08-14 15:20:58.502184: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7383dfc95eee45eab523505cd44f420a","version_major":2,"version_minor":0},"text/plain":["modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ec07397f46534583b2165319e1f6e1fc","version_major":2,"version_minor":0},"text/plain":["config_sentence_transformers.json:   0%|          | 0.00/128 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"12a7a67ab0664861b39eaa47b1797b38","version_major":2,"version_minor":0},"text/plain":["README.md:   0%|          | 0.00/70.9k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e111e9ac95804c66aeceb25ba467940a","version_major":2,"version_minor":0},"text/plain":["sentence_bert_config.json:   0%|          | 0.00/54.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a45e97cd8e9d44ffac9d2378f52088f4","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/2.03k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"71906980d04e48bcb05214f70295891c","version_major":2,"version_minor":0},"text/plain":["configuration_hf_nomic_bert.py:   0%|          | 0.00/1.96k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["A new version of the following files was downloaded from https://huggingface.co/nomic-ai/nomic-bert-2048:\n","- configuration_hf_nomic_bert.py\n",". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"24461c414e0a466b89d45b68a0092555","version_major":2,"version_minor":0},"text/plain":["modeling_hf_nomic_bert.py:   0%|          | 0.00/84.7k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["A new version of the following files was downloaded from https://huggingface.co/nomic-ai/nomic-bert-2048:\n","- modeling_hf_nomic_bert.py\n",". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"71ba1193e7cc4b508ff2dc5c12b64d18","version_major":2,"version_minor":0},"text/plain":["pytorch_model.bin:   0%|          | 0.00/547M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3059304590154f158f9a4f9dd62c718f","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/1.19k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e8fa64bf0fb84a6b8cf3b22d478d2e55","version_major":2,"version_minor":0},"text/plain":["vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"54fe25bd9ac64b83b84d4db3801d59b9","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fe298568aa5543f9983ec39ec5b02c18","version_major":2,"version_minor":0},"text/plain":["special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"66db6dce758b4d129acee2f77eb506f0","version_major":2,"version_minor":0},"text/plain":["1_Pooling/config.json:   0%|          | 0.00/270 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["from transformers import DPRContextEncoder, AutoProcessor, DPRContextEncoderTokenizer, BlipModel,TrOCRProcessor, VisionEncoderDecoderModel, ViTFeatureExtractor, AutoTokenizer, BitsAndBytesConfig, BlipForConditionalGeneration\n","#from peft import get_peft_model, LoraConfig, TaskType, prepare_model_for_kbit_training\n","from sentence_transformers import SentenceTransformer\n","\n","\n","# tokenizer = DPRContextEncoderTokenizer.from_pretrained('facebook/dpr-ctx_encoder-single-nq-base', use_fast=False)\n","# embedding_model = DPRContextEncoder.from_pretrained('facebook/dpr-ctx_encoder-single-nq-base').to(device)\n","\n","embedding_model= SentenceTransformer(\"nomic-ai/nomic-embed-text-v1\", trust_remote_code=True)"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-08-14T15:22:42.088586Z","iopub.status.busy":"2024-08-14T15:22:42.087299Z","iopub.status.idle":"2024-08-14T15:22:43.903301Z","shell.execute_reply":"2024-08-14T15:22:43.902026Z","shell.execute_reply.started":"2024-08-14T15:22:42.088490Z"},"trusted":true},"outputs":[],"source":["import os\n","import torch\n","#import clip\n","from PIL import Image\n","#import faiss\n","import numpy as np\n","import json\n","import matplotlib.pyplot as plt\n","import math\n","import googletrans\n","import translate\n","import glob\n","import underthesea\n","import sys\n","import time\n","from tqdm import tqdm\n","from pyvi import ViUtils, ViTokenizer\n","from difflib import SequenceMatcher\n","from langdetect import detect\n","from pathlib import Path\n","import re"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-08-14T15:25:41.902341Z","iopub.status.busy":"2024-08-14T15:25:41.901925Z","iopub.status.idle":"2024-08-14T15:25:41.909987Z","shell.execute_reply":"2024-08-14T15:25:41.908786Z","shell.execute_reply.started":"2024-08-14T15:25:41.902313Z"},"trusted":true},"outputs":[],"source":["ROOT = Path(os.getcwd()).resolve()\n","\n","# Add ROOT to sys.path\n","sys.path.append(str(ROOT))\n","\n","# Determine the working directory\n","if len(ROOT.parents) > 1:\n","    WORK_DIR = ROOT.parents[0]\n","else:\n","    WORK_DIR = ROOT  # Fallback to ROOT if it doesn't have enough parents\n","\n","# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","# model, preprocess = clip.load(\"ViT-B/32\", device=device)\n","\n","paths = f\"{WORK_DIR}/input/training-aic\"\n","des_path =  f\"{WORK_DIR}/working/dicts/npy_ocr\"\n","os.makedirs(des_path, exist_ok=True)"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-08-14T15:24:34.681806Z","iopub.status.busy":"2024-08-14T15:24:34.680624Z","iopub.status.idle":"2024-08-14T15:24:34.688547Z","shell.execute_reply":"2024-08-14T15:24:34.687080Z","shell.execute_reply.started":"2024-08-14T15:24:34.681758Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["/kaggle/working/dicts/npy_ocr\n"]}],"source":["print(des_path)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["paths = \"/kaggle/input/training-aic\"\n","des_path = \"/kaggle/working/\""]},{"cell_type":"code","execution_count":53,"metadata":{"execution":{"iopub.execute_input":"2024-08-14T15:48:27.242743Z","iopub.status.busy":"2024-08-14T15:48:27.242308Z","iopub.status.idle":"2024-08-14T15:48:27.264321Z","shell.execute_reply":"2024-08-14T15:48:27.262378Z","shell.execute_reply.started":"2024-08-14T15:48:27.242711Z"},"trusted":true},"outputs":[],"source":["class Text_Preprocessing():\n","    def __init__(self, stopwords_path=f\"/kaggle/input/stopword/vietnamese-stopwords-dash.txt\"):\n","        with open(stopwords_path, 'r', encoding='utf-8') as f:  # Open in text mode for easier string handling\n","            self.stop_words = [line.strip() for line in f.readlines()]\n","\n","    def find_substring(self, string1, string2):\n","        match = SequenceMatcher(None, string1, string2, autojunk=False).find_longest_match(0, len(string1), 0, len(string2))\n","        return string1[match.a:match.a + match.size].strip()\n","\n","    def remove_stopwords(self, text):\n","        text = ViTokenizer.tokenize(text)\n","        filtered_words = [w for w in text.split() if w not in self.stop_words]\n","        return \" \".join(filtered_words)\n","\n","    def lowercasing(self, text):\n","        return text.lower()\n","\n","    def uppercasing(self, text):\n","        return text.upper()\n","\n","    def add_accents(self, text):\n","        return ViUtils.add_accents(text)\n","\n","    def remove_accents(self, text):\n","        return ViUtils.remove_accents(text)\n","\n","    def sentence_segment(self, text):\n","        return underthesea.sent_tokenize(text)\n","\n","    def text_norm(self, text):\n","        return underthesea.text_normalize(text)\n","\n","    def text_classify(self, text):\n","        return underthesea.classify(text)\n","\n","    def sentiment_analysis(self, text):\n","        return underthesea.sentiment(text)\n","\n","    def __call__(self, text):\n","        # Apply preprocessing steps\n","        text = self.lowercasing(text)\n","        #text = self.remove_stopwords(text)\n","        # Uncomment and adjust as needed\n","        # text = self.remove_accents(text)\n","        # text = self.add_accents(text)\n","        text = self.text_norm(text)\n","        return text  # Return the processed text\n","\n","class Translation():\n","    def __init__(self, from_lang='vi', to_lang='en', mode='google'):\n","        # The class Translation is a wrapper for the two translation libraries, googletrans and translate.\n","        self.__mode = mode\n","        self.__from_lang = from_lang\n","        self.__to_lang = to_lang\n","        self.text_processing = Text_Preprocessing()\n","        if mode in 'googletrans':\n","            self.translator = googletrans.Translator()\n","        elif mode in 'translate':\n","            self.translator = translate.Translator(from_lang=from_lang,to_lang=to_lang)\n","\n","    def preprocessing(self, text):\n","\n","        return self.text_processing(text) #text.lower()\n","\n","    def __call__(self, text):\n","\n","        text = self.preprocessing(text)\n","        return self.translator.translate(text) if self.__mode in 'translate' \\\n","                else self.translator.translate(text, dest=self.__to_lang).text\n","\n"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-08-15T01:08:35.495843Z","iopub.status.busy":"2024-08-15T01:08:35.495390Z","iopub.status.idle":"2024-08-15T01:08:38.823358Z","shell.execute_reply":"2024-08-15T01:08:38.822176Z","shell.execute_reply.started":"2024-08-15T01:08:35.495805Z"},"trusted":true},"outputs":[],"source":["import easyocr\n","reader = easyocr.Reader(['vi','en']) # this needs to run only once to load the model into memory\n","\n","# Function to perform OCR on an image and return text\n","def ocr_image(image_path):\n","    image = Image.open(image_path).convert(\"RGB\")\n","    pixel_values = processor(image, return_tensors=\"pt\").pixel_values\n","    generated_ids = model.generate(pixel_values)\n","    generated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n","    return generated_text\n","def easyocr_image(image_path):\n","    texts = []\n","    result = reader.readtext(image_path)\n","\n","    for i in result:\n","        if i[2] >0.3:\n","            print(i[2],i[1])\n","            texts.append(i[1])\n","    merged_text = \"\\n\".join(texts)\n","    return merged_text\n","\n"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-08-15T01:09:08.945211Z","iopub.status.busy":"2024-08-15T01:09:08.943982Z","iopub.status.idle":"2024-08-15T01:09:17.403551Z","shell.execute_reply":"2024-08-15T01:09:17.402332Z","shell.execute_reply.started":"2024-08-15T01:09:08.945172Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["0.5724026217395257 Hd\n","0.9774045414527394 Phú Yên:\n","0.585883441024281 lớn dánh chìm tàu dánh cá ngay cửa biển,\n","0.7139053604617218 người mất tích\n","0.31164787461920734 Phú Yên: Triêl\n","0.9989473819732666 Sóng\n"]}],"source":["text = easyocr_image('/kaggle/input/training-aic/Keyframes_L31/L31_V002/025.jpg')"]},{"cell_type":"code","execution_count":49,"metadata":{"execution":{"iopub.execute_input":"2024-08-14T15:45:36.285637Z","iopub.status.busy":"2024-08-14T15:45:36.285065Z","iopub.status.idle":"2024-08-14T15:47:22.966062Z","shell.execute_reply":"2024-08-14T15:47:22.963105Z","shell.execute_reply.started":"2024-08-14T15:45:36.285601Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["  0%|          | 0/2 [00:00<?, ?it/s]\n","  0%|          | 0/241 [00:00<?, ?it/s]\u001b[A"]},{"name":"stdout","output_type":"stream","text":["FUSHP\n","06829843\n","06829843\n","06829843\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"72cbec094d8e4630902bd4e5b93a387f","version_major":2,"version_minor":0},"text/plain":["Batches:   0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 1/241 [00:09<36:57,  9.24s/it]\u001b[A"]},{"name":"stdout","output_type":"stream","text":["IH\n","7SHD\n","06829847\n","IH\n","06829847\n","ih 06829847\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"870b9a50b87e44c99c1f1c555f81edc8","version_major":2,"version_minor":0},"text/plain":["Batches:   0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\n","  1%|          | 2/241 [00:17<35:24,  8.89s/it]\u001b[A"]},{"name":"stdout","output_type":"stream","text":["IF\n","TS\n","Hd\n","06:29248\n","TS\n","Hd\n","06:29248\n","ts hd 06 : 29248\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0c78ec274b2647c487ed21e471c5d30d","version_major":2,"version_minor":0},"text/plain":["Batches:   0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\n","  1%|          | 3/241 [00:26<35:12,  8.88s/it]\u001b[A"]},{"name":"stdout","output_type":"stream","text":["I7]\n","TvI?\n","GJD\n","16829851\n","giây\n","16829851\n","giây\n","16829851 giây\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e90457d26e7c4de0b46988de2581f2e0","version_major":2,"version_minor":0},"text/plain":["Batches:   0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\n","  2%|▏         | 4/241 [00:35<34:59,  8.86s/it]\u001b[A"]},{"name":"stdout","output_type":"stream","text":["HLV\n","HP\n","06829858\n","VĨNH PHÚ\n","MỸ KHÔI\n","giây\n","06829858\n","VĨNH PHÚ\n","MỸ KHÔI\n","giây\n","06829858 vĩnh_phú mỹ_khôi giây\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f3528d9f46db4420bdb365ae036b466c","version_major":2,"version_minor":0},"text/plain":["Batches:   0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\n","  2%|▏         | 5/241 [00:44<35:22,  8.99s/it]\u001b[A"]},{"name":"stdout","output_type":"stream","text":["HLLI\n","HD\n","06830805\n","giây\n","HD\n","06830805\n","giây\n","hd 06830805 giây\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a1a1626881ee4b619f4a8ee5ecf5aa72","version_major":2,"version_minor":0},"text/plain":["Batches:   0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\n","  2%|▏         | 6/241 [00:53<34:37,  8.84s/it]\u001b[A"]},{"name":"stdout","output_type":"stream","text":["FTTSHD\n","06.30.10\n","06.30.10\n","06.30.10\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"64adbfcd134d4a8eb2f0957dca377457","version_major":2,"version_minor":0},"text/plain":["Batches:   0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\n","  3%|▎         | 7/241 [01:01<34:04,  8.74s/it]\u001b[A"]},{"name":"stdout","output_type":"stream","text":["1\n","79HD\n","06:30:12\n","THẢO\n","DAI\n","DỰ\n","ĐẤT\n","Đổl\n","LUẬT\n","SỬA\n","79HD\n","06:30:12\n","THẢO\n","DAI\n","DỰ\n","ĐẤT\n","Đổl\n","LUẬT\n","SỬA\n","79 hd 06 : 30 : 12 _thảo dai dự đất đổl luật sửa\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ffb4c864afa84bb78894a6d42b243d3a","version_major":2,"version_minor":0},"text/plain":["Batches:   0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\n","  3%|▎         | 8/241 [01:11<34:46,  8.96s/it]\u001b[A"]},{"name":"stdout","output_type":"stream","text":["IH\n","TS\n","GD\n","06830817\n","Qúj\n","@Èe \n","E\n","Alac\n","@knke\n","TS\n","06830817\n","E\n","ts 06830817 e\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"52b866beda174795bfee48eb97f7e1de","version_major":2,"version_minor":0},"text/plain":["Batches:   0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\n","  4%|▎         | 9/241 [01:20<34:19,  8.88s/it]\u001b[A"]},{"name":"stdout","output_type":"stream","text":["Kaffi\n","BeNTV\n","Kaff\n","IF\n","7V]\n","HD\n","06830820\n","TIN CHÍNH\n","LcG\n","giây\n","TP-HCM TÌM CÁCH \"GIẢI CỨU\" BẾN XE MIÊN ĐÔNG MỚI\n","7V]\n","HD\n","06830820\n","TIN CHÍNH\n","LcG\n","giây\n","TP-HCM TÌM CÁCH \"GIẢI CỨU\" BẾN XE MIÊN ĐÔNG MỚI\n","7 v ] hd 06830820 lcg giây tp - hcm \" giải_cứu \" bến_xe miên đông\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"57a1e2ab2a544348883c31bf77251b86","version_major":2,"version_minor":0},"text/plain":["Batches:   0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\n","  4%|▍         | 10/241 [01:29<34:23,  8.93s/it]\u001b[A"]},{"name":"stdout","output_type":"stream","text":["IG\n","IS\n","BP\n","06830822\n","24\n","ac\n","Nalava\n","IS\n","06830822\n","24\n","is 06830822 24\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"66797dc33a144516bd1f4d6fafb47890","version_major":2,"version_minor":0},"text/plain":["Batches:   0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\n","  5%|▍         | 11/241 [01:45<36:36,  9.55s/it]\u001b[A\n","  0%|          | 0/2 [01:45<?, ?it/s]\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[49], line 20\u001b[0m\n\u001b[1;32m     12\u001b[0m keyframe_paths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(keyframe_paths, key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x : x\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m keyframe_path \u001b[38;5;129;01min\u001b[39;00m tqdm(keyframe_paths):\n\u001b[1;32m     15\u001b[0m \n\u001b[1;32m     16\u001b[0m \n\u001b[1;32m     17\u001b[0m   \u001b[38;5;66;03m#text = ocr_image(keyframe_path)\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \n\u001b[1;32m     19\u001b[0m   \u001b[38;5;66;03m#//////////////////////////////////\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m   text \u001b[38;5;241m=\u001b[39m \u001b[43measyocr_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyframe_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m   \u001b[38;5;66;03m#//////////////////////////////////\u001b[39;00m\n\u001b[1;32m     24\u001b[0m   text \u001b[38;5;241m=\u001b[39m Translate(text)\n","Cell \u001b[0;32mIn[45], line 13\u001b[0m, in \u001b[0;36measyocr_image\u001b[0;34m(image_path)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21measyocr_image\u001b[39m(image_path):\n\u001b[1;32m     12\u001b[0m     texts \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 13\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mreader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadtext\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m result:\n\u001b[1;32m     16\u001b[0m         \u001b[38;5;28mprint\u001b[39m(i[\u001b[38;5;241m1\u001b[39m])\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/easyocr/easyocr.py:456\u001b[0m, in \u001b[0;36mReader.readtext\u001b[0;34m(self, image, decoder, beamWidth, batch_size, workers, allowlist, blocklist, detail, rotation_info, paragraph, min_size, contrast_ths, adjust_contrast, filter_ths, text_threshold, low_text, link_threshold, canvas_size, mag_ratio, slope_ths, ycenter_ths, height_ths, width_ths, y_ths, x_ths, add_margin, threshold, bbox_min_score, bbox_min_size, max_candidates, output_format)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    451\u001b[0m \u001b[38;5;124;03mParameters:\u001b[39;00m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;124;03mimage: file path or numpy-array or a byte stream object\u001b[39;00m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    454\u001b[0m img, img_cv_grey \u001b[38;5;241m=\u001b[39m reformat_input(image)\n\u001b[0;32m--> 456\u001b[0m horizontal_list, free_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43mmin_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmin_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_threshold\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtext_threshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m    458\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43mlow_text\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlow_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlink_threshold\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlink_threshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43mcanvas_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcanvas_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmag_ratio\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmag_ratio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43mslope_ths\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mslope_ths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mycenter_ths\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mycenter_ths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m    461\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43mheight_ths\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mheight_ths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwidth_ths\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mwidth_ths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m    462\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43madd_margin\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43madd_margin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreformat\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m    463\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbbox_min_score\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbbox_min_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m    464\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43mbbox_min_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbbox_min_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_candidates\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmax_candidates\u001b[49m\n\u001b[1;32m    465\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    466\u001b[0m \u001b[38;5;66;03m# get the 1st result from hor & free list as self.detect returns a list of depth 3\u001b[39;00m\n\u001b[1;32m    467\u001b[0m horizontal_list, free_list \u001b[38;5;241m=\u001b[39m horizontal_list[\u001b[38;5;241m0\u001b[39m], free_list[\u001b[38;5;241m0\u001b[39m]\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/easyocr/easyocr.py:321\u001b[0m, in \u001b[0;36mReader.detect\u001b[0;34m(self, img, min_size, text_threshold, low_text, link_threshold, canvas_size, mag_ratio, slope_ths, ycenter_ths, height_ths, width_ths, add_margin, reformat, optimal_num_chars, threshold, bbox_min_score, bbox_min_size, max_candidates)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reformat:\n\u001b[1;32m    319\u001b[0m     img, img_cv_grey \u001b[38;5;241m=\u001b[39m reformat_input(img)\n\u001b[0;32m--> 321\u001b[0m text_box_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_textbox\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    323\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mcanvas_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcanvas_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    324\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mmag_ratio\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmag_ratio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    325\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mtext_threshold\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtext_threshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    326\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mlink_threshold\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlink_threshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    327\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mlow_text\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlow_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    328\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mpoly\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    329\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    330\u001b[0m \u001b[43m                            \u001b[49m\u001b[43moptimal_num_chars\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43moptimal_num_chars\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    331\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    332\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mbbox_min_score\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbbox_min_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    333\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mbbox_min_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbbox_min_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    334\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mmax_candidates\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmax_candidates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    335\u001b[0m \u001b[43m                            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    337\u001b[0m horizontal_list_agg, free_list_agg \u001b[38;5;241m=\u001b[39m [], []\n\u001b[1;32m    338\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m text_box \u001b[38;5;129;01min\u001b[39;00m text_box_list:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/easyocr/detection.py:95\u001b[0m, in \u001b[0;36mget_textbox\u001b[0;34m(detector, image, canvas_size, mag_ratio, text_threshold, link_threshold, low_text, poly, device, optimal_num_chars, **kwargs)\u001b[0m\n\u001b[1;32m     93\u001b[0m result \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     94\u001b[0m estimate_num_chars \u001b[38;5;241m=\u001b[39m optimal_num_chars \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 95\u001b[0m bboxes_list, polys_list \u001b[38;5;241m=\u001b[39m \u001b[43mtest_net\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcanvas_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmag_ratio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdetector\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43mlink_threshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlow_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpoly\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mestimate_num_chars\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimate_num_chars:\n\u001b[1;32m    100\u001b[0m     polys_list \u001b[38;5;241m=\u001b[39m [[p \u001b[38;5;28;01mfor\u001b[39;00m p, _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(polys, key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28mabs\u001b[39m(optimal_num_chars \u001b[38;5;241m-\u001b[39m x[\u001b[38;5;241m1\u001b[39m]))]\n\u001b[1;32m    101\u001b[0m                   \u001b[38;5;28;01mfor\u001b[39;00m polys \u001b[38;5;129;01min\u001b[39;00m polys_list]\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/easyocr/detection.py:46\u001b[0m, in \u001b[0;36mtest_net\u001b[0;34m(canvas_size, mag_ratio, net, image, text_threshold, link_threshold, low_text, poly, device, estimate_num_chars)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# forward pass\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 46\u001b[0m     y, feature \u001b[38;5;241m=\u001b[39m \u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m boxes_list, polys_list \u001b[38;5;241m=\u001b[39m [], []\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m out \u001b[38;5;129;01min\u001b[39;00m y:\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;66;03m# make score and link map\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/easyocr/craft.py:64\u001b[0m, in \u001b[0;36mCRAFT.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\" U network \"\"\"\u001b[39;00m\n\u001b[1;32m     63\u001b[0m y \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([sources[\u001b[38;5;241m0\u001b[39m], sources[\u001b[38;5;241m1\u001b[39m]], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 64\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m y \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39minterpolate(y, size\u001b[38;5;241m=\u001b[39msources[\u001b[38;5;241m2\u001b[39m]\u001b[38;5;241m.\u001b[39msize()[\u001b[38;5;241m2\u001b[39m:], mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbilinear\u001b[39m\u001b[38;5;124m'\u001b[39m, align_corners\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     67\u001b[0m y \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([y, sources[\u001b[38;5;241m2\u001b[39m]], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/easyocr/craft.py:26\u001b[0m, in \u001b[0;36mdouble_conv.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 26\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/container.py:215\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 215\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    454\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    455\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["Translate = Translation()\n","for keyframe in tqdm(os.listdir(paths)):\n","  path_keyframe = os.path.join(paths,keyframe)\n","  video_paths = sorted(glob.glob(f\"{path_keyframe}/*/\"))\n","  video_paths = ['/'.join(i.split('/')[:-1]) for i in video_paths]\n","\n","  start_time = time.time()\n","  for vd_path in video_paths:\n","\n","    re_feats = []\n","    keyframe_paths = glob.glob(f'{vd_path}/*.jpg')\n","    keyframe_paths = sorted(keyframe_paths, key=lambda x : x.split('/')[-1].replace('.jpg',''))\n","\n","    for keyframe_path in tqdm(keyframe_paths):\n","      \n","      #text = ocr_image(keyframe_path)\n","\n","      #//////////////////////////////////\n","      text = easyocr_image(keyframe_path)\n","        \n","      #//////////////////////////////////\n","     \n","      text = Translate(text)\n","\n","      # Convert text to embedding vector\n","      #embedding = embedding_model(**tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True,max_length=512, add_special_tokens = True)).pooler_output.detach().numpy()\n","      embeddings = embedding_model.encode(text)\n","      # Append embedding to re_feats list\n","      re_feats.append(embeddings)\n","\n","    name_npy = vd_path.split('/')[-1]\n","\n","    # Construct output file path\n","    outfile = os.path.join(des_path, f'{name_npy}.npy')\n","\n","    # Ensure the directory exists before saving\n","    os.makedirs(des_path, exist_ok=True)\n","    np.save(outfile, re_feats)\n","    print(f\"Processed {vd_path} in {time.time() - start_time} seconds\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["feature_shape = 512\n","\n","\n","def write_bin_file_ocr(bin_path: str, npy_path: str, method='cosine'):\n","    if method in 'L2':\n","      index = faiss.IndexFlatL2(feature_shape)\n","    elif method in 'cosine':\n","      index = faiss.IndexFlatIP(feature_shape)\n","    else:\n","      assert f\"{method} not supported\"\n","    npy_files = glob.glob(os.path.join(npy_path, \"*.npy\"))\n","    npy_files_sorted = sorted(npy_files)\n","\n","    for npy_file in npy_files_sorted:\n","        feats = np.load(npy_file)\n","        print(f\"Loaded {npy_file}, shape: {feats.shape}\")\n","\n","\n","        # Convert to float32 and reshape to match feature_shape\n","        feats = feats.astype(np.float32)\n","        feats = feats.reshape(-1, feats.shape[-1])\n","\n","        # Resize or trim feats_normalized to match feature_shape if necessary\n","        if feats.shape[1] != feature_shape:\n","            feats = feats[:, :feature_shape]\n","\n","        assert feats.shape[1] == feature_shape, \\\n","            f\"Query features dimension {feats.shape[1]} do not match index dimension {feature_shape}\"\n","\n","        # Add to Faiss index\n","        index.add(feats)\n","\n","    # Write the Faiss index to disk\n","    faiss.write_index(index, os.path.join(bin_path, f\"faiss_OCR_{method}.bin\"))\n","    print(f'Saved {os.path.join(bin_path, f\"faiss_OCR_{method}.bin\")}')\n","\n","\n","# write ocr\n","write_bin_file_ocr(bin_path=f\"{WORK_DIR}/data/dicts/bin_ocr\", npy_path=f\"{WORK_DIR}/data/dicts/npy_ocr\")\n","\n"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":5370474,"sourceId":8928036,"sourceType":"datasetVersion"},{"datasetId":5544043,"sourceId":9173734,"sourceType":"datasetVersion"}],"dockerImageVersionId":30746,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
