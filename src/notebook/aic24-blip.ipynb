{"cells":[{"cell_type":"code","execution_count":7,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: bitsandbytes in /home/duong/anaconda3/envs/aic/lib/python3.8/site-packages (0.43.3)\n","Requirement already satisfied: torch in /home/duong/anaconda3/envs/aic/lib/python3.8/site-packages (from bitsandbytes) (1.7.1)\n","Requirement already satisfied: numpy in /home/duong/anaconda3/envs/aic/lib/python3.8/site-packages (from bitsandbytes) (1.24.3)\n","Requirement already satisfied: typing-extensions in /home/duong/anaconda3/envs/aic/lib/python3.8/site-packages (from torch->bitsandbytes) (4.12.2)\n","Note: you may need to restart the kernel to use updated packages.\n","Requirement already satisfied: transformers in /home/duong/anaconda3/envs/aic/lib/python3.8/site-packages (4.44.0)\n","Requirement already satisfied: filelock in /home/duong/anaconda3/envs/aic/lib/python3.8/site-packages (from transformers) (3.13.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /home/duong/anaconda3/envs/aic/lib/python3.8/site-packages (from transformers) (0.24.5)\n","Requirement already satisfied: numpy>=1.17 in /home/duong/anaconda3/envs/aic/lib/python3.8/site-packages (from transformers) (1.24.3)\n","Requirement already satisfied: packaging>=20.0 in /home/duong/anaconda3/envs/aic/lib/python3.8/site-packages (from transformers) (24.1)\n","Requirement already satisfied: pyyaml>=5.1 in /home/duong/anaconda3/envs/aic/lib/python3.8/site-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /home/duong/anaconda3/envs/aic/lib/python3.8/site-packages (from transformers) (2024.5.15)\n","Requirement already satisfied: requests in /home/duong/anaconda3/envs/aic/lib/python3.8/site-packages (from transformers) (2.32.3)\n","Requirement already satisfied: safetensors>=0.4.1 in /home/duong/anaconda3/envs/aic/lib/python3.8/site-packages (from transformers) (0.4.4)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /home/duong/anaconda3/envs/aic/lib/python3.8/site-packages (from transformers) (0.19.1)\n","Requirement already satisfied: tqdm>=4.27 in /home/duong/anaconda3/envs/aic/lib/python3.8/site-packages (from transformers) (4.66.4)\n","Requirement already satisfied: fsspec>=2023.5.0 in /home/duong/anaconda3/envs/aic/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/duong/anaconda3/envs/aic/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /home/duong/anaconda3/envs/aic/lib/python3.8/site-packages (from requests->transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /home/duong/anaconda3/envs/aic/lib/python3.8/site-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /home/duong/anaconda3/envs/aic/lib/python3.8/site-packages (from requests->transformers) (2.2.2)\n","Requirement already satisfied: certifi>=2017.4.17 in /home/duong/anaconda3/envs/aic/lib/python3.8/site-packages (from requests->transformers) (2024.7.4)\n","Note: you may need to restart the kernel to use updated packages.\n","Collecting flash-attn\n","  Using cached flash_attn-2.6.3.tar.gz (2.6 MB)\n","  Preparing metadata (setup.py) ... \u001b[?25lerror\n","  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n","  \n","  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n","  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n","  \u001b[31m╰─>\u001b[0m \u001b[31m[20 lines of output]\u001b[0m\n","  \u001b[31m   \u001b[0m fatal: not a git repository (or any of the parent directories): .git\n","  \u001b[31m   \u001b[0m \n","  \u001b[31m   \u001b[0m \n","  \u001b[31m   \u001b[0m torch.__version__  = 2.4.0\n","  \u001b[31m   \u001b[0m \n","  \u001b[31m   \u001b[0m \n","  \u001b[31m   \u001b[0m /tmp/pip-install-3e7yeyci/flash-attn_914243b39ddc426c96138a23ec073b8f/setup.py:95: UserWarning: flash_attn was requested, but nvcc was not found.  Are you sure your environment has nvcc available?  If you're installing within a container from https://hub.docker.com/r/pytorch/pytorch, only images whose names contain 'devel' will provide nvcc.\n","  \u001b[31m   \u001b[0m   warnings.warn(\n","  \u001b[31m   \u001b[0m Traceback (most recent call last):\n","  \u001b[31m   \u001b[0m   File \"<string>\", line 2, in <module>\n","  \u001b[31m   \u001b[0m   File \"<pip-setuptools-caller>\", line 34, in <module>\n","  \u001b[31m   \u001b[0m   File \"/tmp/pip-install-3e7yeyci/flash-attn_914243b39ddc426c96138a23ec073b8f/setup.py\", line 179, in <module>\n","  \u001b[31m   \u001b[0m     CUDAExtension(\n","  \u001b[31m   \u001b[0m   File \"/home/duong/anaconda3/envs/aic/lib/python3.8/site-packages/torch/utils/cpp_extension.py\", line 1076, in CUDAExtension\n","  \u001b[31m   \u001b[0m     library_dirs += library_paths(cuda=True)\n","  \u001b[31m   \u001b[0m   File \"/home/duong/anaconda3/envs/aic/lib/python3.8/site-packages/torch/utils/cpp_extension.py\", line 1207, in library_paths\n","  \u001b[31m   \u001b[0m     if (not os.path.exists(_join_cuda_home(lib_dir)) and\n","  \u001b[31m   \u001b[0m   File \"/home/duong/anaconda3/envs/aic/lib/python3.8/site-packages/torch/utils/cpp_extension.py\", line 2416, in _join_cuda_home\n","  \u001b[31m   \u001b[0m     raise OSError('CUDA_HOME environment variable is not set. '\n","  \u001b[31m   \u001b[0m OSError: CUDA_HOME environment variable is not set. Please set it to your CUDA install root.\n","  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n","  \n","  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n","\u001b[?25h\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n","\n","\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n","\u001b[31m╰─>\u001b[0m See above for output.\n","\n","\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n","\u001b[1;36mhint\u001b[0m: See above for details.\n","Note: you may need to restart the kernel to use updated packages.\n","Collecting sentence-transformers\n","  Using cached sentence_transformers-3.0.1-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: transformers<5.0.0,>=4.34.0 in /home/duong/anaconda3/envs/aic/lib/python3.8/site-packages (from sentence-transformers) (4.44.0)\n","Requirement already satisfied: tqdm in /home/duong/anaconda3/envs/aic/lib/python3.8/site-packages (from sentence-transformers) (4.66.4)\n","Collecting torch>=1.11.0 (from sentence-transformers)\n","  Using cached torch-2.4.0-cp38-cp38-manylinux1_x86_64.whl.metadata (26 kB)\n","Requirement already satisfied: numpy in /home/duong/anaconda3/envs/aic/lib/python3.8/site-packages (from sentence-transformers) (1.24.3)\n","Requirement already satisfied: scikit-learn in /home/duong/anaconda3/envs/aic/lib/python3.8/site-packages (from sentence-transformers) (1.3.2)\n","Requirement already satisfied: scipy in /home/duong/anaconda3/envs/aic/lib/python3.8/site-packages (from sentence-transformers) (1.10.1)\n","Requirement already satisfied: huggingface-hub>=0.15.1 in /home/duong/anaconda3/envs/aic/lib/python3.8/site-packages (from sentence-transformers) (0.24.5)\n","Requirement already satisfied: Pillow in /home/duong/anaconda3/envs/aic/lib/python3.8/site-packages (from sentence-transformers) (10.2.0)\n","Requirement already satisfied: filelock in /home/duong/anaconda3/envs/aic/lib/python3.8/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.13.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /home/duong/anaconda3/envs/aic/lib/python3.8/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2024.6.1)\n","Requirement already satisfied: packaging>=20.9 in /home/duong/anaconda3/envs/aic/lib/python3.8/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (24.1)\n","Requirement already satisfied: pyyaml>=5.1 in /home/duong/anaconda3/envs/aic/lib/python3.8/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0.1)\n","Requirement already satisfied: requests in /home/duong/anaconda3/envs/aic/lib/python3.8/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.32.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/duong/anaconda3/envs/aic/lib/python3.8/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.12.2)\n","Requirement already satisfied: sympy in /home/duong/anaconda3/envs/aic/lib/python3.8/site-packages (from torch>=1.11.0->sentence-transformers) (1.12)\n","Requirement already satisfied: networkx in /home/duong/anaconda3/envs/aic/lib/python3.8/site-packages (from torch>=1.11.0->sentence-transformers) (3.1)\n","Requirement already satisfied: jinja2 in /home/duong/anaconda3/envs/aic/lib/python3.8/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.11.0->sentence-transformers)\n","  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.11.0->sentence-transformers)\n","  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.11.0->sentence-transformers)\n","  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.11.0->sentence-transformers)\n","  Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.11.0->sentence-transformers)\n","  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.11.0->sentence-transformers)\n","  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.11.0->sentence-transformers)\n","  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.11.0->sentence-transformers)\n","  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.11.0->sentence-transformers)\n","  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/duong/anaconda3/envs/aic/lib/python3.8/site-packages (from torch>=1.11.0->sentence-transformers) (2.20.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/duong/anaconda3/envs/aic/lib/python3.8/site-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n","Requirement already satisfied: triton==3.0.0 in /home/duong/anaconda3/envs/aic/lib/python3.8/site-packages (from torch>=1.11.0->sentence-transformers) (3.0.0)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/duong/anaconda3/envs/aic/lib/python3.8/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence-transformers) (12.6.20)\n","Requirement already satisfied: regex!=2019.12.17 in /home/duong/anaconda3/envs/aic/lib/python3.8/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (2024.5.15)\n","Requirement already satisfied: safetensors>=0.4.1 in /home/duong/anaconda3/envs/aic/lib/python3.8/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.4.4)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /home/duong/anaconda3/envs/aic/lib/python3.8/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.19.1)\n","Requirement already satisfied: joblib>=1.1.1 in /home/duong/anaconda3/envs/aic/lib/python3.8/site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /home/duong/anaconda3/envs/aic/lib/python3.8/site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /home/duong/anaconda3/envs/aic/lib/python3.8/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /home/duong/anaconda3/envs/aic/lib/python3.8/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /home/duong/anaconda3/envs/aic/lib/python3.8/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /home/duong/anaconda3/envs/aic/lib/python3.8/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2.2.2)\n","Requirement already satisfied: certifi>=2017.4.17 in /home/duong/anaconda3/envs/aic/lib/python3.8/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2024.7.4)\n","Requirement already satisfied: mpmath>=0.19 in /home/duong/anaconda3/envs/aic/lib/python3.8/site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n","Using cached sentence_transformers-3.0.1-py3-none-any.whl (227 kB)\n","Using cached torch-2.4.0-cp38-cp38-manylinux1_x86_64.whl (797.2 MB)\n","Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n","Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","Installing collected packages: nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusolver-cu12, nvidia-cudnn-cu12, torch, sentence-transformers\n","  Attempting uninstall: torch\n","    Found existing installation: torch 1.7.1\n","    Uninstalling torch-1.7.1:\n","      Successfully uninstalled torch-1.7.1\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","clip-by-openai 1.1 requires torch<1.7.2,>=1.7.1, but you have torch 2.4.0 which is incompatible.\n","clip-by-openai 1.1 requires torchvision==0.8.2, but you have torchvision 0.19.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 sentence-transformers-3.0.1 torch-2.4.0\n","Note: you may need to restart the kernel to use updated packages.\n","Collecting xformers\n","  Using cached xformers-0.0.27.post2-cp38-cp38-manylinux2014_x86_64.whl.metadata (1.0 kB)\n","Requirement already satisfied: numpy in /home/duong/anaconda3/envs/aic/lib/python3.8/site-packages (from xformers) (1.24.3)\n","Requirement already satisfied: torch==2.4.0 in /home/duong/anaconda3/envs/aic/lib/python3.8/site-packages (from xformers) (2.4.0)\n","Requirement already satisfied: filelock in /home/duong/anaconda3/envs/aic/lib/python3.8/site-packages (from torch==2.4.0->xformers) (3.13.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /home/duong/anaconda3/envs/aic/lib/python3.8/site-packages (from torch==2.4.0->xformers) (4.12.2)\n","Requirement already satisfied: sympy in /home/duong/anaconda3/envs/aic/lib/python3.8/site-packages (from torch==2.4.0->xformers) (1.12)\n","Requirement already satisfied: networkx in /home/duong/anaconda3/envs/aic/lib/python3.8/site-packages (from torch==2.4.0->xformers) (3.1)\n","Requirement already satisfied: jinja2 in /home/duong/anaconda3/envs/aic/lib/python3.8/site-packages (from torch==2.4.0->xformers) (3.1.4)\n","Requirement already satisfied: fsspec in /home/duong/anaconda3/envs/aic/lib/python3.8/site-packages (from torch==2.4.0->xformers) (2024.6.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /home/duong/anaconda3/envs/aic/lib/python3.8/site-packages (from jinja2->torch==2.4.0->xformers) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /home/duong/anaconda3/envs/aic/lib/python3.8/site-packages (from sympy->torch==2.4.0->xformers) (1.3.0)\n","Using cached xformers-0.0.27.post2-cp38-cp38-manylinux2014_x86_64.whl (20.8 MB)\n","Installing collected packages: xformers\n","Successfully installed xformers-0.0.27.post2\n","Note: you may need to restart the kernel to use updated packages.\n"]}],"source":["# %pip install -q translate\n","# %pip install -q underthesea==1.3.5a3\n","# %pip install -q underthesea[deep]\n","# %pip install -q pyvi\n","# %pip install -q langdetect\n","# %pip install -q googletrans==3.1.0a0\n","# %pip install -q peft\n","%pip install bitsandbytes\n","%pip install transformers\n","%pip install flash-attn\n","%pip install -U sentence-transformers\n","%pip install xformers"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Note: you may need to restart the kernel to use updated packages.\n"]}],"source":["# %pip install -q faiss-cpu\n","%pip install -q git+https://github.com/openai/CLIP.git"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/duong/anaconda3/envs/aic/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]}],"source":["import os\n","import torch\n","import clip\n","from PIL import Image\n","import faiss\n","import numpy as np\n","import json\n","import matplotlib.pyplot as plt\n","import math\n","import googletrans\n","import translate\n","import glob\n","import underthesea\n","import sys\n","import time\n","from tqdm import tqdm\n","from pyvi import ViUtils, ViTokenizer\n","from difflib import SequenceMatcher\n","from langdetect import detect\n","from pathlib import Path\n","import re\n","from transformers import BlipForConditionalGeneration\n"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["/home/duong/Documents/AIC2024_UTE_AI_Unknown/src\n","/home/duong/Documents/AIC2024_UTE_AI_Unknown/data/keyframes\n"]}],"source":["ROOT = Path(os.getcwd()).resolve()\n","\n","# Add ROOT to sys.path\n","sys.path.append(str(ROOT))\n","\n","# Determine the working directory\n","if len(ROOT.parents) > 1:\n","    WORK_DIR = ROOT.parents[0]\n","else:\n","    WORK_DIR = ROOT  # Fallback to ROOT if it doesn't have enough parents\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model, preprocess = clip.load(\"ViT-B/32\", device=device)\n","\n","paths = f\"{WORK_DIR}/data/keyframes\"\n","des_path =  f\"{WORK_DIR}/working//dicts/npy_blip\"\n","os.makedirs(des_path, exist_ok=True)\n","print(WORK_DIR)\n","\n","if len(WORK_DIR.parents) > 1:\n","    WORK_DIR2 = WORK_DIR.parents[0]\n","else:\n","    WORK_DIR2 = WORK_DIR  # Fallback to ROOT if it doesn't have enough parents\n","path2 = f\"{WORK_DIR2}/data/keyframes\"\n","print(path2)\n"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/duong/anaconda3/envs/aic/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n","/home/duong/.cache/huggingface/modules/transformers_modules/nomic-ai/nomic-bert-2048/e55a7d4324f65581af5f483e830b80f34680e8ff/modeling_hf_nomic_bert.py:95: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  state_dict = loader(resolved_archive_file)\n","<All keys matched successfully>\n"]}],"source":["from transformers import DPRContextEncoder, AutoProcessor, DPRContextEncoderTokenizer, BlipModel,TrOCRProcessor, VisionEncoderDecoderModel, ViTFeatureExtractor, AutoTokenizer, BitsAndBytesConfig, BlipForConditionalGeneration\n","#from peft import get_peft_model, LoraConfig, TaskType, prepare_model_for_kbit_training\n","from sentence_transformers import SentenceTransformer\n","\n","\n","# tokenizer = DPRContextEncoderTokenizer.from_pretrained('facebook/dpr-ctx_encoder-single-nq-base', use_fast=False)\n","# embedding_model = DPRContextEncoder.from_pretrained('facebook/dpr-ctx_encoder-single-nq-base').to(device)\n","\n","embedding_model= SentenceTransformer(\"nomic-ai/nomic-embed-text-v1\", trust_remote_code=True)"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"ename":"NameError","evalue":"name 'AutoProcessor' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[7], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m BlipForConditionalGeneration\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSalesforce/blip-image-captioning-base\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#Another model \u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m processor \u001b[38;5;241m=\u001b[39m \u001b[43mAutoProcessor\u001b[49m\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSalesforce/blip-image-captioning-base\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","\u001b[0;31mNameError\u001b[0m: name 'AutoProcessor' is not defined"]}],"source":["model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n","#Another model for Blip\n","# https://huggingface.co/models?sort=trending&search=blip\n","processor = AutoProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["def blip_image(image_path):\n","  image = Image.open(image_path)\n","  inputs = processor(images=image, return_tensors=\"pt\").to(device)\n","  pixel_values = inputs.pixel_values\n","\n","  generated_ids = model.generate(pixel_values=pixel_values, max_length=50)\n","  generated_caption = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n","  return generated_caption"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 235/235 [04:10<00:00,  1.07s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Processed /home/duong/Documents/AIC2024_UTE_AI_Unknown/data/keyframes/Keyframes_L30/L30_V001 in 250.8251929283142 seconds\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 273/273 [04:49<00:00,  1.06s/it]\n"," 50%|█████     | 1/2 [09:00<09:00, 540.02s/it]"]},{"name":"stdout","output_type":"stream","text":["Processed /home/duong/Documents/AIC2024_UTE_AI_Unknown/data/keyframes/Keyframes_L30/L30_V002 in 540.0229551792145 seconds\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 241/241 [03:57<00:00,  1.01it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Processed /home/duong/Documents/AIC2024_UTE_AI_Unknown/data/keyframes/Keyframes_L31/L31_V001 in 237.96122980117798 seconds\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 244/244 [03:53<00:00,  1.05it/s]\n","100%|██████████| 2/2 [16:51<00:00, 505.71s/it]"]},{"name":"stdout","output_type":"stream","text":["Processed /home/duong/Documents/AIC2024_UTE_AI_Unknown/data/keyframes/Keyframes_L31/L31_V002 in 471.39397144317627 seconds\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["\n","for keyframe in tqdm(os.listdir(path2)):\n","  path_keyframe = os.path.join(path2,keyframe)\n","  video_paths = sorted(glob.glob(f\"{path_keyframe}/*/\"))\n","  video_paths = ['/'.join(i.split('/')[:-1]) for i in video_paths]\n","\n","  start_time = time.time()\n","  for vd_path in video_paths:\n","\n","    re_feats = []\n","    keyframe_paths = glob.glob(f'{vd_path}/*.jpg')\n","    keyframe_paths = sorted(keyframe_paths, key=lambda x : x.split('/')[-1].replace('.jpg',''))\n","\n","    for keyframe_path in tqdm(keyframe_paths):\n","\n","\n","      #text = ocr_image(keyframe_path)\n","\n","      #//////////////////////////////////\n","      text = blip_image(keyframe_path)\n","      #//////////////////////////////////\n","      if detect(text) == 'vi' :\n","        text = Translation(text)\n","\n","      # Convert text to embedding vector\n","      #embedding = embedding_model(**tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True,max_length=512, add_special_tokens = True)).pooler_output.detach().numpy()\n","      embeddings = embedding_model.encode(text)\n","      # Append embedding to re_feats list\n","      re_feats.append(embeddings)\n","\n","    name_npy = vd_path.split('/')[-1]\n","\n","    # Construct output file path\n","    outfile = os.path.join(des_path, f'{name_npy}.npy')\n","\n","    # Ensure the directory exists before saving\n","    os.makedirs(des_path, exist_ok=True)\n","    np.save(outfile, re_feats)\n","\n","    print(f\"Processed {vd_path} in {time.time() - start_time} seconds\")\n"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Loaded /home/duong/Documents/AIC2024_UTE_AI_Unknown/src/working/dicts/npy_blip/L30_V001.npy, shape: (235, 768)\n","Loaded /home/duong/Documents/AIC2024_UTE_AI_Unknown/src/working/dicts/npy_blip/L30_V002.npy, shape: (273, 768)\n","Loaded /home/duong/Documents/AIC2024_UTE_AI_Unknown/src/working/dicts/npy_blip/L31_V001.npy, shape: (241, 768)\n","Loaded /home/duong/Documents/AIC2024_UTE_AI_Unknown/src/working/dicts/npy_blip/L31_V002.npy, shape: (244, 768)\n","Saved /home/duong/Documents/AIC2024_UTE_AI_Unknown/src/working/dicts/bin_blip/faiss_BLIP_cosine.bin\n"]}],"source":["feature_shape = 384\n","\n","\n","def write_bin_file_ocr(bin_path: str, npy_path: str, method='cosine'):\n","    if method in 'L2':\n","      index = faiss.IndexFlatL2(feature_shape)\n","    elif method in 'cosine':\n","      index = faiss.IndexFlatIP(feature_shape)\n","    else:\n","      assert f\"{method} not supported\"\n","    npy_files = glob.glob(os.path.join(npy_path, \"*.npy\"))\n","    npy_files_sorted = sorted(npy_files)\n","\n","    for npy_file in npy_files_sorted:\n","        feats = np.load(npy_file)\n","        print(f\"Loaded {npy_file}, shape: {feats.shape}\")\n","\n","\n","        # Convert to float32 and reshape to match feature_shape\n","        feats = feats.astype(np.float32)\n","        feats = feats.reshape(-1, feats.shape[-1])\n","\n","        # Resize or trim feats_normalized to match feature_shape if necessary\n","        if feats.shape[1] != feature_shape:\n","            feats = feats[:, :feature_shape]\n","\n","        assert feats.shape[1] == feature_shape, \\\n","            f\"Query features dimension {feats.shape[1]} do not match index dimension {feature_shape}\"\n","\n","        # Add to Faiss index\n","        index.add(feats)\n","\n","    # Write the Faiss index to disk\n","    faiss.write_index(index, os.path.join(bin_path, f\"faiss_BLIP_{method}.bin\"))\n","    print(f'Saved {os.path.join(bin_path, f\"faiss_BLIP_{method}.bin\")}')\n","\n","\n","# write ocr\n","write_bin_file_ocr(bin_path=f\"{WORK_DIR}/working/dicts/bin_blip\", npy_path=f\"{WORK_DIR}/working/dicts/npy_blip\")\n","\n"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[],"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.19"}},"nbformat":4,"nbformat_minor":4}
