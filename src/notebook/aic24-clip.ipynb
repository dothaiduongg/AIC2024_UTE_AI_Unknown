{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q faiss-cpu\n!pip install -q git+https://github.com/openai/CLIP.git","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install -q translate\n!pip install -q underthesea==1.3.5a3\n!pip install -q underthesea[deep]\n!pip install -q pyvi\n!pip install -q langdetect\n!pip install -q googletrans==3.1.0a0\n!pip install -q peft\n!pip install bitsandbytes\n!pip install transformers\n!pip install flash-attn\n!pip install -U sentence-transformers\n!pip install xformers","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport torch\nimport clip\nfrom PIL import Image\nimport faiss\nimport numpy as np\nimport json\nimport matplotlib.pyplot as plt\nimport math\nimport googletrans\nimport translate\nimport glob\nimport underthesea\nimport sys\nimport time\nfrom tqdm import tqdm\nfrom pyvi import ViUtils, ViTokenizer\nfrom difflib import SequenceMatcher\nfrom langdetect import detect\nfrom pathlib import Path\nimport re","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ROOT = Path(os.getcwd()).resolve()\n\n# Add ROOT to sys.path\nsys.path.append(str(ROOT))\n\n# Determine the working directory\nif len(ROOT.parents) > 1:\n    WORK_DIR = ROOT.parents[0]\nelse:\n    WORK_DIR = ROOT  # Fallback to ROOT if it doesn't have enough parents\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel, preprocess = clip.load(\"ViT-B/32\", device=device)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"des_path =  f\"{WORK_DIR}/data/dicts/npy_clip\"\npaths = f\"{WORK_DIR}/data/keyframes\"\n\n\nfor keyframe in tqdm(os.listdir(paths)):\n  path_keyframe = os.path.join(paths,keyframe)\n  video_paths = sorted(glob.glob(f\"{path_keyframe}/*/\"))\n  video_paths = ['/'.join(i.split('/')[:-1]) for i in video_paths]\n\n  start_time = time.time()\n  for vd_path in video_paths:\n\n    re_feats = []\n    keyframe_paths = glob.glob(f'{vd_path}/*.jpg')\n    keyframe_paths = sorted(keyframe_paths, key=lambda x : x.split('/')[-1].replace('.jpg',''))\n\n    for keyframe_path in keyframe_paths:\n      image = preprocess(Image.open(keyframe_path)).unsqueeze(0).to(device)\n\n      with torch.no_grad():\n          image_feats = model.encode_image(image)\n\n      image_feats /= image_feats.norm(dim=-1, keepdim=True)\n      image_feats = image_feats.detach().cpu().numpy().astype(np.float16).flatten()\n\n      re_feats.append(image_feats)\n\n    name_npy = vd_path.split('/')[-1]\n\n# Construct output file path\n    outfile = os.path.join(des_path, f'{name_npy}.npy')\n\n# Ensure the directory exists before saving\n    os.makedirs(des_path, exist_ok=True)\n    np.save(outfile, re_feats)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def process_name(name: int):\n    return \"0\"*(6-len(str(name))) + str(name)\n\ndef sort_key(file_path):\n    file_name = os.path.basename(file_path)\n    match = re.match(r'(\\D+)(\\d+)_(V)(\\d+)', file_name)\n    if match:\n        prefix = match.group(1)\n        number = int(match.group(2))\n        suffix_number = int(match.group(4))\n        return (prefix, number, suffix_number)\n    return (file_name, 0, 0)\n\n\ndef write_bin_file_clip(bin_path: str, npy_path: str  ,method='cosine', feature_shape= 512): # Edit 512, 768\n  if method in 'L2':\n    index = faiss.IndexFlatL2(feature_shape)\n  elif method in 'cosine':\n    index = faiss.IndexFlatIP(feature_shape)\n  else:\n    assert f\"{method} not supported\"\n\n  npy_files = glob.glob(os.path.join(npy_path, \"*.npy\"))\n  npy_files_sorted = sorted(npy_files, key=sort_key)\n\n  for npy_file in npy_files_sorted:\n    feats = np.load(npy_file)\n    index.add(feats)\n\n  faiss.write_index(index, os.path.join(bin_path, f\"faiss_CLIP_{method}.bin\"))\n\n  print(f'Saved {os.path.join(bin_path, f\"faiss_CLIP_{method}.bin\")}')\n\nwrite_bin_file_clip(bin_path = f\"{WORK_DIR}/data/dicts/bin_clip\", npy_path = f\"{WORK_DIR}/data/dicts/npy_clip\")\n","metadata":{},"execution_count":null,"outputs":[]}]}